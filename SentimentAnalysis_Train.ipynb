{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis - Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweets = pd.read_csv('tweets2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tweet_sentiment(tweet):\n",
    "        analysis = TextBlob(tweet)\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>1714</td>\n",
       "      <td>1714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>7057</td>\n",
       "      <td>7057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>9106</td>\n",
       "      <td>9106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet  sentiment\n",
       "sentiment                  \n",
       "negative    1714       1714\n",
       "neutral     7057       7057\n",
       "positive    9106       9106"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_tweets['sentiment'] = cleaned_tweets.apply(lambda x: get_tweet_sentiment(x['tweet']),axis = 1)\n",
    "cleaned_tweets.groupby(cleaned_tweets['sentiment']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = cleaned_tweets['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stop words and do frequency analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "stopwords = ['the','to','a','is','and','for','i','you','in','on','with','of','this','we','have','your','my','are','have',\\\n",
    "             'from','-',':','rt','via','can','when','by','but','+'] + list(ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "for line in text:\n",
    "    word = line.split()\n",
    "    words+=word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for term in words:\n",
    "    if term in stopwords:\n",
    "        words.remove(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('oneplus', 8899), ('the', 4536), ('6t', 4343), ('new', 1625), ('purple', 1608), ('thunder', 1484), ('a', 1362), ('#oneplus6t', 1342), ('6', 1265), ('phone', 1193), ('you', 1031), ('win', 1005), ('video', 953), ('this', 943), ('giveaway', 822), ('to', 807), ('best', 783), ('color', 767), ('backpack', 762), ('black', 695), ('free', 685), ('vs', 623), ('i', 615), (':', 595), ('my', 568), ('check', 567), ('and', 557), ('android', 554), ('is', 543), ('with', 541), ('are', 533), ('have', 524), ('your', 523), ('liked', 505), ('we', 499), ('just', 497), ('explorer', 485), ('hands', 476), ('galaxy', 473), ('3', 470)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "count = Counter()\n",
    "allterms = [term for term in words]\n",
    "count.update(allterms)\n",
    "print(count.most_common(40)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = re.compile(u'[^\\+]')\n",
    "list1 = [x for x in allterms if regex.match(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regex = re.compile(u'[^\\#]')\n",
    "list2 = [x for x in list1 if regex.match(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regex = re.compile(u'[^0-9]')\n",
    "list3 = [x for x in list2 if regex.match(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regex = re.compile(u'[^\\|]')\n",
    "list4 = [x for x in list3 if regex.match(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regex = re.compile(u'[^*\\+\\#*]')\n",
    "okay_items = [x for x in list4 if regex.match(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test at a ratio of 70:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text, y = cleaned_tweets.tweet, cleaned_tweets.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_train, text_test, y_train, y_test = train_test_split(text, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'neutral', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    1176\n",
       "neutral     4720\n",
       "positive    6081\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.groupby(y_train,axis=0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'neutral', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative     538\n",
       "neutral     2337\n",
       "positive    3025\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.groupby(y_test,axis=0).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rescaling the Data with tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the approaches to extract features from test is to\n",
    "rescale features by how informative we expect them to be. One of the most common\n",
    "ways to do this is using the term frequencyâ€“inverse document frequency (tf-idf)\n",
    "method. Let us create a function for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfidf_extractor(corpus, ngram_range=(1,1)):    \n",
    "    vectorizer = TfidfVectorizer(min_df=1, \n",
    "                                 norm='l2',\n",
    "                                 smooth_idf=True,\n",
    "                                 use_idf=True,\n",
    "                                 ngram_range=ngram_range)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    #Productionize features\n",
    "    pickle.dump(vectorizer.vocabulary_,open(\"feature.pkl\",\"wb\"))\n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer, tfidf_train_features = tfidf_extractor(text_train)  \n",
    "tfidf_test_features = tfidf_vectorizer.transform(text_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selector = SelectKBest(f_classif, k=min(400,tfidf_train_features.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selector.fit(tfidf_train_features, y_train)\n",
    "tfidf_train_features = selector.transform(tfidf_train_features)\n",
    "tfidf_test_features = selector.transform(tfidf_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_selector = selector.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Productionize Feature selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(test_selector,open(\"selector.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11977x400 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 78551 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_metrics(true_labels, predicted_labels):\n",
    "    print ('Accuracy:', np.round(metrics.accuracy_score(true_labels,predicted_labels),2))\n",
    "    print ('Precision:', np.round(metrics.precision_score(true_labels,predicted_labels,average='weighted'),2))\n",
    "    print ('Recall:', np.round(metrics.recall_score(true_labels, predicted_labels,average='weighted'),2))\n",
    "    print ('F1 Score:', np.round(metrics.f1_score(true_labels, predicted_labels,average='weighted'),2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_predict_evaluate_model(name, classifier,train_features, train_labels, test_features, test_labels):\n",
    "    # build model    \n",
    "    classifier.fit(train_features, train_labels)\n",
    "    # predict using model\n",
    "    predictions = classifier.predict(test_features) \n",
    "    #Productionize model\n",
    "    modelname = name + \".pkl\"\n",
    "    pickle.dump(classifier,open(modelname,\"wb\"))\n",
    "    # evaluate model prediction performance   \n",
    "    get_metrics(true_labels=test_labels, \n",
    "                predicted_labels=predictions)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes with tfidf features   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnb_best = MultinomialNB(alpha = 0.001,fit_prior = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n",
      "Precision: 0.76\n",
      "Recall: 0.73\n",
      "F1 Score: 0.72\n"
     ]
    }
   ],
   "source": [
    "mnb_tfidf_predictions = train_predict_evaluate_model(name = \"NaiveBayes\", classifier=mnb_best,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=y_train,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>260</td>\n",
       "      <td>49</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>1240</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>165</td>\n",
       "      <td>2827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2\n",
       "0  260    49   229\n",
       "1   32  1240  1065\n",
       "2   33   165  2827"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_test, mnb_tfidf_predictions)\n",
    "pd.DataFrame(cm, index=range(0,3), columns=range(0,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_best = SGDClassifier(loss='hinge', max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "Precision: 0.9\n",
      "Recall: 0.89\n",
      "F1 Score: 0.89\n"
     ]
    }
   ],
   "source": [
    "svm_tfidf_predictions = train_predict_evaluate_model(name = \"SVM\", classifier=svm_best,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=y_train,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>175</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>2286</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>361</td>\n",
       "      <td>2644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2\n",
       "0  313   175    50\n",
       "1    9  2286    42\n",
       "2   20   361  2644"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_test, svm_tfidf_predictions)\n",
    "pd.DataFrame(cm, index=range(0,3), columns=range(0,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorrect Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label: positive\n",
      "Predicted Label: neutral\n",
      "Review: rt :    my favorite #oneplus6t is #thunderpurple ++retweeted the tweet+followed all thr...\n",
      "Actual Label: positive\n",
      "Predicted Label: neutral\n",
      "Review: my favourite #oneplus6t is #mirrorblack  coz it is bold and elegant+subsc...\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "score = ['positive','negative','neutral']\n",
    "for document, label, predicted_label in zip(text_test, y_test, svm_tfidf_predictions):\n",
    "    for i in score:\n",
    "        if label == i and predicted_label != i:\n",
    "            print (\"Actual Label:\", label)\n",
    "            print (\"Predicted Label:\", predicted_label)\n",
    "            print (\"Review:\", re.sub('\\n', ' ', document))\n",
    "    num += 1\n",
    "    if num == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label: negative\n",
      "Predicted Label: negative\n",
      "Review: how an anime game's root detection led to the discovery of a security vulnerability in phones from lg, oneplus, hua...\n",
      "Actual Label: positive\n",
      "Predicted Label: positive\n",
      "Review: black friday 2018 phone deals: free oneplus 6t now, lg v40 with free $500 tv, moto g6 for $200 - cnet\n",
      "Actual Label: neutral\n",
      "Predicted Label: neutral\n",
      "Review: it is a oneplus 6 - it's in a carbon fibre style case\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "score = ['positive','negative','neutral']\n",
    "for document, label, predicted_label in zip(text_test, y_test, svm_tfidf_predictions):\n",
    "    for i in score:\n",
    "        if label == i and predicted_label == i:\n",
    "            print (\"Actual Label:\", label)\n",
    "            print (\"Predicted Label:\", predicted_label)\n",
    "            print (\"Review:\", re.sub('\\n', ' ', document))\n",
    "    num += 1\n",
    "    if num == 5:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
